{
  "model": "llama-3.1-8b-instant",
  "dataset": "dev.json",
  "total_examples": 10,
  "exact_match_accuracy": 0.0,
  "execution_match_accuracy": 0.5,
  "execution_success_rate": 0.9,
  "error_rate": 0.0,
  "average_time_per_query": 0.396213960647583,
  "total_time": 3.96213960647583,
  "per_database_accuracy": {
    "flight_2": {
      "exact_match_accuracy": 0.0,
      "execution_match_accuracy": 0.5,
      "execution_success_rate": 0.5,
      "total_examples": 2
    },
    "pets_1": {
      "exact_match_accuracy": 0.0,
      "execution_match_accuracy": 1.0,
      "execution_success_rate": 1.0,
      "total_examples": 2
    },
    "student_transcripts_tracking": {
      "exact_match_accuracy": 0.0,
      "execution_match_accuracy": 1.0,
      "execution_success_rate": 1.0,
      "total_examples": 1
    },
    "battle_death": {
      "exact_match_accuracy": 0.0,
      "execution_match_accuracy": 0.0,
      "execution_success_rate": 1.0,
      "total_examples": 1
    },
    "wta_1": {
      "exact_match_accuracy": 0.0,
      "execution_match_accuracy": 0.0,
      "execution_success_rate": 1.0,
      "total_examples": 1
    },
    "employee_hire_evaluation": {
      "exact_match_accuracy": 0.0,
      "execution_match_accuracy": 0.0,
      "execution_success_rate": 1.0,
      "total_examples": 1
    },
    "car_1": {
      "exact_match_accuracy": 0.0,
      "execution_match_accuracy": 0.0,
      "execution_success_rate": 1.0,
      "total_examples": 1
    },
    "network_1": {
      "exact_match_accuracy": 0.0,
      "execution_match_accuracy": 1.0,
      "execution_success_rate": 1.0,
      "total_examples": 1
    }
  }
}