{
  "model": "llama-3.1-8b-instant",
  "dataset": "dev.json",
  "total_examples": 1034,
  "exact_match_accuracy": 0.07833655705996131,
  "execution_match_accuracy": 0.4932301740812379,
  "execution_success_rate": 0.776595744680851,
  "error_rate": 0.06866537717601548,
  "average_time_per_query": 0.585515680350003,
  "total_time": 605.4232134819031,
  "per_database_accuracy": {
    "concert_singer": {
      "exact_match_accuracy": 0.044444444444444446,
      "execution_match_accuracy": 0.5333333333333333,
      "execution_success_rate": 0.7111111111111111,
      "total_examples": 45
    },
    "pets_1": {
      "exact_match_accuracy": 0.11904761904761904,
      "execution_match_accuracy": 0.40476190476190477,
      "execution_success_rate": 0.7142857142857143,
      "total_examples": 42
    },
    "car_1": {
      "exact_match_accuracy": 0.13043478260869565,
      "execution_match_accuracy": 0.358695652173913,
      "execution_success_rate": 0.6630434782608695,
      "total_examples": 92
    },
    "flight_2": {
      "exact_match_accuracy": 0.0875,
      "execution_match_accuracy": 0.8125,
      "execution_success_rate": 0.8625,
      "total_examples": 80
    },
    "employee_hire_evaluation": {
      "exact_match_accuracy": 0.07894736842105263,
      "execution_match_accuracy": 0.5789473684210527,
      "execution_success_rate": 0.868421052631579,
      "total_examples": 38
    },
    "cre_Doc_Template_Mgt": {
      "exact_match_accuracy": 0.07142857142857142,
      "execution_match_accuracy": 0.6666666666666666,
      "execution_success_rate": 0.8571428571428571,
      "total_examples": 84
    },
    "course_teach": {
      "exact_match_accuracy": 0.03333333333333333,
      "execution_match_accuracy": 0.4666666666666667,
      "execution_success_rate": 0.7,
      "total_examples": 30
    },
    "museum_visit": {
      "exact_match_accuracy": 0.05555555555555555,
      "execution_match_accuracy": 0.5,
      "execution_success_rate": 0.7222222222222222,
      "total_examples": 18
    },
    "wta_1": {
      "exact_match_accuracy": 0.08064516129032258,
      "execution_match_accuracy": 0.2903225806451613,
      "execution_success_rate": 0.7419354838709677,
      "total_examples": 62
    },
    "battle_death": {
      "exact_match_accuracy": 0.1875,
      "execution_match_accuracy": 0.5,
      "execution_success_rate": 0.75,
      "total_examples": 16
    },
    "student_transcripts_tracking": {
      "exact_match_accuracy": 0.08974358974358974,
      "execution_match_accuracy": 0.5,
      "execution_success_rate": 0.7564102564102564,
      "total_examples": 78
    },
    "tvshow": {
      "exact_match_accuracy": 0.06451612903225806,
      "execution_match_accuracy": 0.4838709677419355,
      "execution_success_rate": 0.7903225806451613,
      "total_examples": 62
    },
    "poker_player": {
      "exact_match_accuracy": 0.25,
      "execution_match_accuracy": 0.85,
      "execution_success_rate": 1.0,
      "total_examples": 40
    },
    "voter_1": {
      "exact_match_accuracy": 0.0,
      "execution_match_accuracy": 0.7333333333333333,
      "execution_success_rate": 0.8,
      "total_examples": 15
    },
    "world_1": {
      "exact_match_accuracy": 0.008333333333333333,
      "execution_match_accuracy": 0.19166666666666668,
      "execution_success_rate": 0.75,
      "total_examples": 120
    },
    "orchestra": {
      "exact_match_accuracy": 0.1,
      "execution_match_accuracy": 0.725,
      "execution_success_rate": 0.9,
      "total_examples": 40
    },
    "network_1": {
      "exact_match_accuracy": 0.017857142857142856,
      "execution_match_accuracy": 0.42857142857142855,
      "execution_success_rate": 0.8571428571428571,
      "total_examples": 56
    },
    "dog_kennels": {
      "exact_match_accuracy": 0.0,
      "execution_match_accuracy": 0.34146341463414637,
      "execution_success_rate": 0.5975609756097561,
      "total_examples": 82
    },
    "singer": {
      "exact_match_accuracy": 0.23333333333333334,
      "execution_match_accuracy": 0.8,
      "execution_success_rate": 0.9,
      "total_examples": 30
    },
    "real_estate_properties": {
      "exact_match_accuracy": 0.5,
      "execution_match_accuracy": 0.5,
      "execution_success_rate": 1.0,
      "total_examples": 4
    }
  },
  "has_gold_sql": true,
  "few_shot_examples": [
    {
      "question": "Who performed the song named \"Le Pop\"?",
      "query": "SELECT T2.firstname ,  T2.lastname FROM Performance AS T1 JOIN Band AS T2 ON T1.bandmate  =  T2.id JOIN Songs AS T3 ON T3.SongId  =  T1.SongId WHERE T3.Title  =  \"Le Pop\""
    },
    {
      "question": "Tell me the types of the policy used by the customer named \"Dayana Robel\".",
      "query": "SELECT DISTINCT t3.policy_type_code FROM customers AS t1 JOIN customers_policies AS t2 ON t1.customer_id  =  t2.customer_id JOIN available_policies AS t3 ON t2.policy_id  =  t3.policy_id WHERE t1.customer_name  =  \"Dayana Robel\""
    },
    {
      "question": "What are the different ids and names of the stations that have had more than 12 bikes available?",
      "query": "SELECT DISTINCT T1.id ,  T1.name FROM station AS T1 JOIN status AS T2 ON T1.id  =  T2.station_id WHERE T2.bikes_available  >  12"
    }
  ]
}